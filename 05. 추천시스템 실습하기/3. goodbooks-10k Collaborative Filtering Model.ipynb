{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Goodbooks-10k \n",
    "- Link : https://www.kaggle.com/zygmunt/goodbooks-10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine \n",
    "from plotnine import *\n",
    "import os, sys, gc\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['books.csv', 'book_tags.csv', 'ratings.csv', 'sample_book.xml', 'tags.csv', 'test.csv', 'to_read.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "path = './input/books/'\n",
    "print(os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(path + \"books.csv\")\n",
    "book_tags = pd.read_csv(path + \"book_tags.csv\")\n",
    "train = pd.read_csv(path + \"train.csv\")\n",
    "test = pd.read_csv(path + \"test.csv\")\n",
    "tags = pd.read_csv(path + \"tags.csv\")\n",
    "to_read = pd.read_csv(path + \"to_read.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['book_id'] = train['book_id'].astype(str)\n",
    "test['book_id'] = test['book_id'].astype(str)\n",
    "books['book_id'] = books['book_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_rec_model = books.sort_values(by='books_count', ascending=False)['book_id'].values[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-03fe4e443b5e>:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8cd77cb4e94c358a67afc7853fb04b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=53424.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sol = test.groupby(['user_id'])['book_id'].agg({'unique'}).reset_index()\n",
    "gt = {}\n",
    "for user in tqdm(sol['user_id'].unique()): \n",
    "    gt[user] = list(sol[sol['user_id'] == user]['unique'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_df = pd.DataFrame()\n",
    "rec_df['user_id'] = train['user_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SGD를 이용한 협업필터링 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Base code : https://yamalab.tistory.com/92\n",
    "class MatrixFactorization():\n",
    "    def __init__(self, R, k, learning_rate, reg_param, epochs, verbose=False):\n",
    "        \"\"\"\n",
    "        :param R: rating matrix\n",
    "        :param k: latent parameter\n",
    "        :param learning_rate: alpha on weight update\n",
    "        :param reg_param: beta on weight update\n",
    "        :param epochs: training epochs\n",
    "        :param verbose: print status\n",
    "        \"\"\"\n",
    "        self._R = R\n",
    "        self._num_users, self._num_items = R.shape\n",
    "        self._k = k\n",
    "        self._learning_rate = learning_rate\n",
    "        self._reg_param = reg_param\n",
    "        self._epochs = epochs\n",
    "        self._verbose = verbose\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        training Matrix Factorization : Update matrix latent weight and bias\n",
    "\n",
    "        참고: self._b에 대한 설명\n",
    "        - global bias: input R에서 평가가 매겨진 rating의 평균값을 global bias로 사용\n",
    "        - 정규화 기능. 최종 rating에 음수가 들어가는 것 대신 latent feature에 음수가 포함되도록 해줌.\n",
    "\n",
    "        :return: training_process\n",
    "        \"\"\"\n",
    "\n",
    "        # init latent features\n",
    "        self._P = np.random.normal(size=(self._num_users, self._k))\n",
    "        self._Q = np.random.normal(size=(self._num_items, self._k))\n",
    "\n",
    "        # init biases\n",
    "        self._b_P = np.zeros(self._num_users)\n",
    "        self._b_Q = np.zeros(self._num_items)\n",
    "        self._b = np.mean(self._R[np.where(self._R != 0)])\n",
    "\n",
    "        # train while epochs\n",
    "        self._training_process = []\n",
    "        for epoch in range(self._epochs):\n",
    "            # rating이 존재하는 index를 기준으로 training\n",
    "            xi, yi = self._R.nonzero()\n",
    "            for i, j in zip(xi, yi):\n",
    "                self.gradient_descent(i, j, self._R[i, j])\n",
    "            cost = self.cost()\n",
    "            self._training_process.append((epoch, cost))\n",
    "\n",
    "            # print status\n",
    "            if self._verbose == True and ((epoch + 1) % 10 == 0):\n",
    "                print(\"Iteration: %d ; cost = %.4f\" % (epoch + 1, cost))\n",
    "\n",
    "\n",
    "    def cost(self):\n",
    "        \"\"\"\n",
    "        compute root mean square error\n",
    "        :return: rmse cost\n",
    "        \"\"\"\n",
    "\n",
    "        # xi, yi: R[xi, yi]는 nonzero인 value를 의미한다.\n",
    "        # 참고: http://codepractice.tistory.com/90\n",
    "        xi, yi = self._R.nonzero()\n",
    "        # predicted = self.get_complete_matrix()\n",
    "        cost = 0\n",
    "        for x, y in zip(xi, yi):\n",
    "            cost += pow(self._R[x, y] - self.get_prediction(x, y), 2)\n",
    "        return np.sqrt(cost/len(xi))\n",
    "\n",
    "\n",
    "    def gradient(self, error, i, j):\n",
    "        \"\"\"\n",
    "        gradient of latent feature for GD\n",
    "\n",
    "        :param error: rating - prediction error\n",
    "        :param i: user index\n",
    "        :param j: item index\n",
    "        :return: gradient of latent feature tuple\n",
    "        \"\"\"\n",
    "\n",
    "        dp = (error * self._Q[j, :]) - (self._reg_param * self._P[i, :])\n",
    "        dq = (error * self._P[i, :]) - (self._reg_param * self._Q[j, :])\n",
    "        return dp, dq\n",
    "\n",
    "\n",
    "    def gradient_descent(self, i, j, rating):\n",
    "        \"\"\"\n",
    "        graident descent function\n",
    "\n",
    "        :param i: user index of matrix\n",
    "        :param j: item index of matrix\n",
    "        :param rating: rating of (i,j)\n",
    "        \"\"\"\n",
    "\n",
    "        # get error\n",
    "        prediction = self.get_prediction(i, j)\n",
    "        error = rating - prediction\n",
    "\n",
    "        # update biases\n",
    "        self._b_P[i] += self._learning_rate * (error - self._reg_param * self._b_P[i])\n",
    "        self._b_Q[j] += self._learning_rate * (error - self._reg_param * self._b_Q[j])\n",
    "\n",
    "        # update latent feature\n",
    "        dp, dq = self.gradient(error, i, j)\n",
    "        self._P[i, :] += self._learning_rate * dp\n",
    "        self._Q[j, :] += self._learning_rate * dq\n",
    "\n",
    "\n",
    "    def get_prediction(self, i, j):\n",
    "        \"\"\"\n",
    "        get predicted rating: user_i, item_j\n",
    "        :return: prediction of r_ij\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[i] + self._b_Q[j] + self._P[i, :].dot(self._Q[j, :].T)\n",
    "\n",
    "\n",
    "    def get_complete_matrix(self):\n",
    "        \"\"\"\n",
    "        computer complete matrix PXQ + P.bias + Q.bias + global bias\n",
    "\n",
    "        - PXQ 행렬에 b_P[:, np.newaxis]를 더하는 것은 각 열마다 bias를 더해주는 것\n",
    "        - b_Q[np.newaxis:, ]를 더하는 것은 각 행마다 bias를 더해주는 것\n",
    "        - b를 더하는 것은 각 element마다 bias를 더해주는 것\n",
    "\n",
    "        - newaxis: 차원을 추가해줌. 1차원인 Latent들로 2차원의 R에 행/열 단위 연산을 해주기위해 차원을 추가하는 것.\n",
    "\n",
    "        :return: complete matrix R^\n",
    "        \"\"\"\n",
    "        return self._b + self._b_P[:, np.newaxis] + self._b_Q[np.newaxis:, ] + self._P.dot(self._Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user2idx = {}\n",
    "for i, l in enumerate(train['user_id'].unique()):\n",
    "    user2idx[l] = i\n",
    "    \n",
    "book2idx = {}\n",
    "for i, l in enumerate(train['book_id'].unique()):\n",
    "    book2idx[l] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2user = {i: user for user, i in user2idx.items()}\n",
    "idx2book = {i: item for item, i in book2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train[['user_id', 'book_id']].reset_index(drop=True)\n",
    "useridx = data['useridx'] = train['user_id'].apply(lambda x: user2idx[x]).values\n",
    "bookidx = data['bookidx'] = train['book_id'].apply(lambda x: book2idx[x]).values\n",
    "rating = np.ones(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<53382x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 386688 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy \n",
    "\n",
    "purchase_sparse = scipy.sparse.csr_matrix((rating, (useridx, bookidx)), shape=(len(set(useridx)), len(set(bookidx))))\n",
    "purchase_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = purchase_sparse.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10 ; cost = 0.4626\n",
      "Iteration: 20 ; cost = 0.3138\n",
      "Iteration: 30 ; cost = 0.2598\n",
      "Iteration: 40 ; cost = 0.2302\n",
      "Iteration: 50 ; cost = 0.2101\n",
      "Iteration: 60 ; cost = 0.1950\n",
      "Iteration: 70 ; cost = 0.1827\n",
      "Iteration: 80 ; cost = 0.1725\n",
      "Iteration: 90 ; cost = 0.1638\n",
      "Iteration: 100 ; cost = 0.1562\n",
      "Wall time: 19min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "factorizer = MatrixFactorization(R, k=20, learning_rate=0.01, reg_param=0.01, epochs=100, verbose=True)\n",
    "factorizer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del R; gc.collect() \n",
    "sgd_rec_model = factorizer.get_complete_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[4893]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[8855]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[9049]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[3273]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[4829, 6703]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        unique\n",
       "0        1        [4893]\n",
       "1        2        [8855]\n",
       "2        3        [9049]\n",
       "3        4        [3273]\n",
       "4        5  [4829, 6703]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 내가 읽은 책의 목록을 추출 \n",
    "read_list = train.groupby(['user_id'])['book_id'].agg({'unique'}).reset_index()\n",
    "read_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-a3efec238c10>:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6049674c21174263876887f3dddb2a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=53382.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_rec_list = {}\n",
    "for user in tqdm(data['useridx'].unique()):\n",
    "    rec_list = []\n",
    "    \n",
    "    # 기존에 만든 Book ID를 변경 \n",
    "    rating_scores = [(idx2book[i], c) for i, c in enumerate(sgd_rec_model[user]) if i != user] # 자기 자신이 추천안되도록 \n",
    "    rating_scores = sorted(rating_scores, key = lambda x: x[1], reverse=True) # 평점이 높은 순서대로 정렬 \n",
    "    \n",
    "    seen = read_list[read_list['user_id'] == idx2user[user]]['unique'].values[0]\n",
    "    for rec in rating_scores[0:250]: \n",
    "        if rec[0] not in seen:\n",
    "            rec_list.append(rec[0])\n",
    "    \n",
    "    if len(rec_list) < 200:\n",
    "        for i in popular_rec_model[0:200]:\n",
    "            if rec not in seen:\n",
    "                rec_list.append(rec)\n",
    "\n",
    "    total_rec_list[idx2user[user]] = rec_list[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import math\n",
    "\n",
    "# https://github.com/kakao-arena/brunch-article-recommendation/blob/master/evaluate.py\n",
    "\n",
    "class evaluate():\n",
    "    def __init__(self, recs, gt, topn=100):\n",
    "        self.recs = recs\n",
    "        self.gt = gt \n",
    "        self.topn = topn \n",
    "        \n",
    "    def _ndcg(self):\n",
    "        Q, S = 0.0, 0.0\n",
    "        for u, seen in six.iteritems(self.gt):\n",
    "            seen = list(set(seen))\n",
    "            rec = self.recs.get(u, [])\n",
    "            if not rec or len(seen) == 0:\n",
    "                continue\n",
    "\n",
    "            dcg = 0.0\n",
    "            idcg = sum([1.0 / math.log(i + 2, 2) for i in range(min(len(seen), len(rec)))])\n",
    "            for i, r in enumerate(rec):\n",
    "                if r not in seen:\n",
    "                    continue\n",
    "                rank = i + 1\n",
    "                dcg += 1.0 / math.log(rank + 1, 2)\n",
    "            ndcg = dcg / idcg\n",
    "            S += ndcg\n",
    "            Q += 1\n",
    "        return S / Q\n",
    "\n",
    "\n",
    "    def _map(self):\n",
    "        n, ap = 0.0, 0.0\n",
    "        for u, seen in six.iteritems(self.gt):\n",
    "            seen = list(set(seen))\n",
    "            rec = self.recs.get(u, [])\n",
    "            if not rec or len(seen) == 0:\n",
    "                continue\n",
    "\n",
    "            _ap, correct = 0.0, 0.0\n",
    "            for i, r in enumerate(rec):\n",
    "                if r in seen:\n",
    "                    correct += 1\n",
    "                    _ap += (correct / (i + 1.0))\n",
    "            _ap /= min(len(seen), len(rec))\n",
    "            ap += _ap\n",
    "            n += 1.0\n",
    "        return ap / n\n",
    "\n",
    "\n",
    "    def _entropy_diversity(self):\n",
    "        sz = float(len(self.recs)) * self.topn\n",
    "        freq = {}\n",
    "        for u, rec in six.iteritems(self.recs):\n",
    "            for r in rec:\n",
    "                freq[r] = freq.get(r, 0) + 1\n",
    "        ent = -sum([v / sz * math.log(v / sz) for v in six.itervalues(freq)])\n",
    "        return ent\n",
    "    \n",
    "    def _evaluate(self):\n",
    "        print('MAP@%s: %s' % (self.topn, self._map()))\n",
    "        print('NDCG@%s: %s' % (self.topn, self._ndcg()))\n",
    "        print('EntDiv@%s: %s' % (self.topn, self._entropy_diversity()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 기존 Author 모델 \n",
    "MAP@200: 0.011817742695221473\n",
    "NDCG@200: 0.004577031690605801\n",
    "EntDiv@200: 5.097773423502677"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP@200: 0.0005719892342333946\n",
      "NDCG@200: 0.005937947293528603\n",
      "EntDiv@200: 8.31100438233348\n"
     ]
    }
   ],
   "source": [
    "evaluate_func = evaluate(recs=total_rec_list, gt = gt, topn=200)\n",
    "evaluate_func._evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS 방식을 이용한 협업필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.evaluation import  *\n",
    "from implicit.als import AlternatingLeastSquares as ALS\n",
    "from implicit.bpr import BayesianPersonalizedRanking as BPR\n",
    "\n",
    "als_model = ALS(factors=20, regularization=0.01, iterations = 100)\n",
    "als_model.fit(purchase_sparse.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_model.recommend(0, purchase_sparse, N=200)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rec_list = {}\n",
    "for user in tqdm(data['useridx'].unique()):\n",
    "    rec_list = []\n",
    "    \n",
    "    # 기존에 만든 Book ID를 변경 \n",
    "    seen = read_list[read_list['user_id'] == idx2user[user]]['unique'].values[0]\n",
    "    recs = als_model.recommend(user, purchase_sparse, N=250)\n",
    "    recs = [idx2book[x[0]] for x in recs][0:250]  \n",
    "    \n",
    "    for rec in recs: \n",
    "        if rec not in seen:\n",
    "            rec_list.append(rec)\n",
    "    \n",
    "    if len(rec_list) < 200:\n",
    "        for i in popular_rec_model[0:200]:\n",
    "            if rec not in seen:\n",
    "                rec_list.append(rec)\n",
    "\n",
    "    total_rec_list[idx2user[user]] = rec_list[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_func = evaluate(recs=total_rec_list, gt = gt, topn=200)\n",
    "evaluate_func._evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
